1. 公司集群规模
十几台左右，机器又有spark，on yarn，hadoop，presto 几个亿
100M 100万 10G 1个亿，1~2G
XLARG vpc 4 内存16G
8vpc 32G 内存
kafka 3台
spring boot 5台 
单层
跳板机

autoscaling 弹性伸缩


阿里云：非常贵。EC2,VPC,OSS.


2. 公司人员配置
后台：十几个
产品：5个以内。
算法：2-3个
数据开发:3-4个 职责划分 工程，算法，leader
oppo和vivio：
算法组，广告，推荐，
工程组：数据收集，数据仓一个组，kafka，spark流计算，调度，集群维护。职责划分
队列的划分：60% 30% 10%
开发,生产,测试环境
大公司，三个环境的。生产环境：运维操作。
测试环境，一个生产环境。
生产环境。
数据仓库：可以直接连的




3. 如何根据公司的数据量和具体业务设计合适的日志采集系统（springboot个数、第一层flume个数等）
autoscaling 架构问题：

数据量，用户数，几十万的日活。几个亿，埋点。100000人的活跃，10，1000000日志数。1000000数据量。
10G/100，0.1G

收集2台，做高可用。
60%-70% 新建机器处理业务，峰值。
flume 1个。
1台机器部署应用。统一部署。运维ansible ，分发到多个机器上面去，启动，配置管理。





4. 如何在数据传输的过程中保证数据的可靠性（不丢失）

kafka consumer,source 
spark offset自动管理。控制maxpartition rate那个参数。
监控预警。应用异常预警，服务奔溃预警，服务器宕机。日志监控，
重跑：kakfa，数据mysql到数据仓库，表之间的etl，重跑etl任务。
中间件的使用，1，大数据量的 2.增量同步的。kafka,mq，S3.
事务补偿操作：提交成功再删除，记录游标。streaming,


5. 在项目过程中遇到过哪些问题，是如何解决的

1.报表：10个小时。
1.有些任务异常，影响后面的任务。
2.有时候整个时间特别长.

晚上12点到早上9点。

任务编排，划分队列，并且进行任务的编排。在一个流程里面的，设置上下关联。执行完成之后。


2.引入presto做响应式查询，给运维提供报表。

3.欧洲美国，两个收集。计算统一放到一个集群进行处理。

欧洲，美国
S3://xxxxx/xxxxx/
s3://xxxx/xxx路径下面。然后统一进行建表操作。离线分析。

写到同一个桶下面，然后监控路径文件的变化，准实时的分析。
java 的线程，监控，新增，减少文件，然后spark去读，最后准实时计算。上个小时，用户的点击情况。

4.kafka吞吐量。
spark streaming，不同的应用，写不同的topic，实时单独拿出来，写topic。kakfa这一层做分离。

5：重跑
每一步执行的，监控linux status 非0异常情况。重跑这个任务。
对这一个报表做处理

6.弹性这个问题。
重跑。配置弹性，跑完数据。

7.join的问题。
数据量特别大。临时表，按时间分开。
切分。抽取相关连的字段。

join ，a 表 id，b 表 id，抽出来。
a，fileter， b 表 id filter 出来。join，这个时候
重写分区器，做join。

8.kafka优化可以调大网络缓存。
读写比较多，用SSD，
JVM参数。

9.hive 表优化
txt，spark 
分区，
关系型的表做分区。


6. 在项目过程中做过哪些优化措施

7. 实时处理时，如何手动维护的offset

8. 公司日志采集系统的离线部分有哪些统计指标，实时部分有哪些统计指标

新闻的指标，

新闻id，语言,字数，图片数，点赞，点踩，关键字，浏览量，视频数，自带热度，，，。威尔逊函数，我们这边的三个月的点击数据。

就包括在一个地区，点击率，时间维度，热度，展示，停留时长，语言，字数，图片数，质量，（推送，展示时间差）。

用户，
活跃用户：id，地区，语言，版本号。

--离线的报表
前后台活跃用户：
后台活跃用户：
前台活跃用户：
用户app停留时长
留存率
新鲜度。
总用户，所有的用户，按天计算，


-- 实时报表：
地区+新闻id+（点击率）热度。
上个小时  地区，语言，新闻总点击，平均点击，总展示，平均展示。


应用：

withcube （时间，地点，语言） 时间，时间+地点，时间+语言，地点+语言，地点，语言，时间+地点+语言





9. 公司中大数据项：的整个开发流程
产品，运营，算法。三种人
我们先开会，确定需求。需求，toDOlist 
算法，产品
需求，有文档，没文档。toDoList 看里面各个需求要花多长时间（开发，考虑测试，bug，跟外部交互），优先级。
谁做，安排任务。
设计文档出，相关人员要来看一下，这个文档是否合理。leader，就这么做。


1。日活掉的很大
2.新闻点击率，5%，20%，产品。 容错，恢复，预警。

kpi。

开发和测试一个环境。生产有个环境。生，产的大数据集群，数据来自，不更新，
不给你用的，运维来用。

开完完成之后，给运营，产品，去看。跟算法，定义调接口，下游





10.大数据开发的开发模式是怎样 需求-设计-开发-测试-验收是怎样的 
11.怎样去估算功能的工时 一般完成一个不是很大的模块大概需要的开发周期要多少 
工时，是否跟外部有交互，多少个功能点。
12.大数据开发的团队模式是怎样的  
工程+算法。
13.大数据开发的开发周期是怎样的 
需求。
敏捷两周一个迭代
14.开发之后与测试人员怎样对接和测试 和Java怎么去对接去实现 可以举一个项目的例子吗 
kafka 定义kafka json格式
{"uid":[newsid1,n2,n3..........]}
{u1,u2,u3}
log
日期|json格式
1537619705000| {
    "appkey": "browser", 
    "he": {
        "userId": "a12234sd", 
        "area": "BR", 
        "appVersion": "V1.0.2",
        "appTime": "1537533305000"
    }, 
    "et": [{
        "eventName": "display", 
        "kv ": {
            "action": "2"，"newsId": "2343234"
        }
    }]
}


15.项目开发之后 验收的形式是怎样的 与Java开发有什么不同 
java web
我们直接给产品，运营，去看
16.项目中的机器规模是怎样 每天多少数据量 目前现有的数据量有多少 
10几台，自动扩展策略，cpu或是内存。几亿的数据量
17.工作中有没有遇到过性能方面的问题 如果有那怎么去解决的 谈一到两个
union解决 join的问题。
a（id,val）
b(id,val2)
select * from a t1 join b t2 on a.id=b.id;
--中间表
create table tmp_a as select id,val,'' val2 from a;

select coaleace from 
select * from tmp_a
union all
select id，‘’ val， val2 from b
group id  

分区器。

18.开发中用Spark需要频繁做RDD的转换 在实现业务的前提下 那有没有一个指标去判断RDD的转换性能上面是达标的 
时间。

19.如何去调试 
测试数据去调试。
中间表查看结果。

20.企业中拿到一个需求，实现业务功能有没有一定的开发步骤和技巧 


